{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load all article reviews from MediaBiasChart V5.0:\n",
    "media_bias = pd.read_csv('../data/MediaBiasChart.csv')\n",
    "media_bias = media_bias.groupby('Source').mean()\n",
    "media_bias.reset_index(level=0, inplace=True)\n",
    "\n",
    "MediaBiasChart_to_Tweet = {'ABC':'ABC','AP':'AP','Axios':'axios','CNN':'CNN','Wall Street Journal':'WSJ',\\\n",
    "    'The Atlantic':'TheAtlantic','The Hill':'thehill', 'BBC':'BBC', 'Think Progress':'thinkprogress',\\\n",
    "    'MSNBC':'MSNBC','The Nation':'thenation','Daily Beast':'thedailybeast','Mother Jones':'MotherJones',\\\n",
    "    'CNSNews':'cnsnews','Fox News':'FoxNews', 'The Federalist':'FDRLST','Breitbart':'BreitbartNews',\\\n",
    "    'Daily Caller':'DailyCaller','The Blaze':'theblaze','Business Insider':'businessinsider',\\\n",
    "    'CBS':'CBSNews','The Economist':'TheEconomist','BuzzFeed':'BuzzFeed','Daily Signal':'DailySignal',\\\n",
    "    'New Republic':'newrepublic','Foreign Policy':'ForeignPolicy','IJR':'TheIJR','National Review':'NRO',\\\n",
    "    'National Public Radio':'NPR','New York Post':'nypost','New York Times':'nytimes','The New Yorker':'NewYorker',\\\n",
    "    'NewsMax':'newsmax','One America News Network':'OANN','Politico':'politico','Quartz':'qz',\\\n",
    "    'Reason':'reason','Reuters':'Reuters','Slate':'Slate','Talking Points Memo':'TPM','Vanity Fair':'VanityFair',\\\n",
    "    'Vox':'voxdotcom','Washington Examiner':'dcexaminer','Washington Free Beacon':'FreeBeacon',\\\n",
    "    'Washington Post':'washingtonpost','Washington Times':'WashTimes','The Week':'TheWeek','Bloomberg':'Bloomberg',\\\n",
    "    'Christian Science Monitor':'csmonitor', 'Democracy Now':'democracynow','Financial Times':'FT',\\\n",
    "    'Fiscal Times':'TheFiscalTimes','Forbes':'Forbes','Fortune':'FortuneMagazine','Forward':'jdforward',\\\n",
    "    'FreeSpeech TV':'freespeechtv','Huffington Post':'HuffPost','LA Times':'latimes','Marketwatch':'MarketWatch',\\\n",
    "    'OZY':'ozy','PBS':'PBS','ProPublica':'propublica','Time':'TIME','USA Today':'USATODAY',\\\n",
    "    'Weather.com':'weatherchannel'}\n",
    "\n",
    "media_bias['Source'] = media_bias.Source.map(MediaBiasChart_to_Tweet)\n",
    "media_bias = media_bias.dropna()\n",
    "media_bias.reset_index(drop=True)\n",
    "\n",
    "\n",
    "frac = 0.2  # This frac stands for the percentage of media to be selected as left/right media\n",
    "left_bound = media_bias.Bias.quantile(frac)\n",
    "right_bound = media_bias.Bias.quantile(1-frac)\n",
    "low_bound = media_bias.Quality.quantile(frac)\n",
    "high_bound = media_bias.Quality.quantile(1-frac)\n",
    "all_media = media_bias['Source'].tolist()\n",
    "left_media = media_bias.loc[media_bias['Bias']<=left_bound]\n",
    "left_media = left_media['Source'].tolist()\n",
    "right_media = media_bias.loc[media_bias['Bias']>=right_bound]\n",
    "right_media = right_media['Source'].tolist()\n",
    "low_media = media_bias.loc[media_bias['Quality']<=low_bound]\n",
    "low_media = low_media['Source'].tolist()\n",
    "high_media = media_bias.loc[media_bias['Quality']>=high_bound]\n",
    "high_media = high_media['Source'].tolist()\n",
    "\n",
    "# Load tweets and filter out a small portion which does not have a proper 'username'\n",
    "df1 = pd.read_csv('../data/filtered_part1.csv', skiprows=1)\n",
    "df2 = pd.read_csv('../data/filtered_part2.csv')\n",
    "df3 = pd.read_csv('../data/filtered_part3.csv')\n",
    "df4 = pd.read_csv('../data/filtered_part4.csv',lineterminator='\\n')\n",
    "df6 = pd.read_csv('../data/filtered_part6.csv')\n",
    "df7 = pd.read_csv('../data/filtered_part7.csv')\n",
    "df8 = pd.read_csv('../data/filtered_part8.csv')\n",
    "df = pd.concat([df1, df2, df3, df4, df6, df7, df8], sort = False)\n",
    "\n",
    "all_media = media_bias['Source'].tolist()\n",
    "df = df.loc[df['user_screen_name'].isin(all_media)]\n",
    "\n",
    "df_2018 = df.loc[((df['created_at']) >= '2018-01-01') & ((df['created_at']) <= '2018-12-31')]\n",
    "df_2018 = df_2018.reset_index(drop = True)\n",
    "import preprocessor as p\n",
    "df_2018['text']  = df_2018['text'].apply(p.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "embedding_dim = 64\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "training_portion = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "media2bias = dict(zip(media_bias.Source, media_bias.Bias))\n",
    "df_2018['bias'] = df_2018['user_screen_name'].map(media2bias)\n",
    "df_2018['bias'] = df_2018['bias']/df_2018['bias'].abs().max()\n",
    "media2qual = dict(zip(media_bias.Source, media_bias.Quality))\n",
    "df_2018['quality'] = df_2018['user_screen_name'].map(media2qual)\n",
    "df_2018['quality'] = df_2018['quality']/df_2018['quality'].abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426493\n",
      "426493\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "labels = []\n",
    "\n",
    "for index, row in df_2018.iterrows():\n",
    "    labels.append(row[['bias','quality']])\n",
    "    article = row['text']\n",
    "    for word in STOPWORDS:\n",
    "        token = ' ' + word + ' '\n",
    "        article = article.replace(token, ' ')\n",
    "        article = article.replace(' ', ' ')\n",
    "    articles.append(article)\n",
    "print(len(labels))\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"If start separate idea movie theaters movies, fact itâ€™s great time.\" Ben Fritz future streaming services movies: https://t.co/tYN2VP17we https://t.co/PFzOcMt6T4'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213246\n",
      "213246\n",
      "213246\n",
      "213247\n",
      "213247\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(articles) * training_portion)\n",
    "\n",
    "train_articles = articles[0: train_size]\n",
    "train_labels = labels[0: train_size]\n",
    "\n",
    "validation_articles = articles[train_size:]\n",
    "validation_labels = labels[train_size:]\n",
    "\n",
    "print(train_size)\n",
    "print(len(train_articles))\n",
    "print(len(train_labels))\n",
    "print(len(validation_articles))\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 't': 2,\n",
       " 'https': 3,\n",
       " 'co': 4,\n",
       " 'trump': 5,\n",
       " 'the': 6,\n",
       " '\\r': 7,\n",
       " 'rt': 8,\n",
       " 'new': 9,\n",
       " 'a': 10}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_articles)\n",
    "word_index = tokenizer.word_index\n",
    "dict(list(word_index.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259, 269, 318, 427, 2177, 95, 1, 1, 95, 2599, 640, 693, 29, 22]\n"
     ]
    }
   ],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_articles)\n",
    "print(train_sequences[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "100\n",
      "6\n",
      "100\n",
      "14\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "print(len(train_sequences[0]))\n",
    "print(len(train_padded[0]))\n",
    "\n",
    "print(len(train_sequences[1]))\n",
    "print(len(train_padded[1]))\n",
    "\n",
    "print(len(train_sequences[10]))\n",
    "print(len(train_padded[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213247\n",
      "(213247, 100)\n"
     ]
    }
   ],
   "source": [
    "validation_sequences = tokenizer.texts_to_sequences(validation_articles)\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "print(len(validation_sequences))\n",
    "print(validation_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4980712   0.69037366]\n",
      "[-0.4980712   0.69037366]\n",
      "[-0.4980712   0.69037366]\n",
      "(213246, 2)\n",
      "[-0.0716953   0.89749014]\n",
      "[-0.0716953   0.89749014]\n",
      "[-0.0716953   0.89749014]\n",
      "(213247, 2)\n"
     ]
    }
   ],
   "source": [
    "training_label_seq = np.array(train_labels).astype('float32')\n",
    "validation_label_seq = np.array(validation_labels).astype('float32')\n",
    "print(training_label_seq[0])\n",
    "print(training_label_seq[1])\n",
    "print(training_label_seq[2])\n",
    "print(training_label_seq.shape)\n",
    "\n",
    "print(validation_label_seq[0])\n",
    "print(validation_label_seq[1])\n",
    "print(validation_label_seq[2])\n",
    "print(validation_label_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there free speech crisis campus itâ€™s <OOV> <OOV> itâ€™s liberty university schools like it ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "---\n",
      "There free speech crisis campus, itâ€™s Yale Middlebury. Itâ€™s Liberty University schools like it.\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_article(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "print(decode_article(train_padded[10]))\n",
    "print('---')\n",
    "print(train_articles[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          320000    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 394,434\n",
      "Trainable params: 394,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    # Add a Dense layer with 6 units and softmax activation.\n",
    "    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 213246 samples, validate on 213247 samples\n",
      "Epoch 1/10\n",
      "213246/213246 - 255s - loss: 0.0620 - val_loss: 0.0607\n",
      "Epoch 2/10\n",
      "213246/213246 - 245s - loss: 0.0535 - val_loss: 0.0603\n",
      "Epoch 3/10\n",
      "213246/213246 - 245s - loss: 0.0485 - val_loss: 0.0611\n",
      "Epoch 4/10\n",
      "213246/213246 - 247s - loss: 0.0439 - val_loss: 0.0617\n",
      "Epoch 5/10\n",
      "213246/213246 - 248s - loss: 0.0395 - val_loss: 0.0640\n",
      "Epoch 6/10\n",
      "213246/213246 - 250s - loss: 0.0356 - val_loss: 0.0656\n",
      "Epoch 7/10\n",
      "213246/213246 - 253s - loss: 0.0320 - val_loss: 0.0679\n",
      "Epoch 8/10\n",
      "213246/213246 - 253s - loss: 0.0290 - val_loss: 0.0703\n",
      "Epoch 9/10\n",
      "213246/213246 - 252s - loss: 0.0263 - val_loss: 0.0698\n",
      "Epoch 10/10\n",
      "213246/213246 - 260s - loss: 0.0241 - val_loss: 0.0728\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=\"mse\")\n",
    "num_epochs = 10\n",
    "history = model.fit(train_padded, training_label_seq, epochs=num_epochs, validation_data=(validation_padded, validation_label_seq), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()\n",
    "  \n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213460\n",
      "213460\n",
      "213033\n",
      "213033\n"
     ]
    }
   ],
   "source": [
    "# In the future, this random sample method should be changed so that each media has exactly a half of tweets being sampled \n",
    "# into train/test...\n",
    "np.random.seed(0)\n",
    "sample = list(np.random.randint(2, size=len(labels)))\n",
    "train_articles = [articles[i] for i in range(len(sample)) if sample[i] == 1]\n",
    "train_labels = [labels[i] for i in range(len(sample)) if sample[i] == 1]\n",
    "validation_articles = [articles[i] for i in range(len(sample)) if sample[i] == 0]\n",
    "validation_labels = [labels[i] for i in range(len(sample)) if sample[i] == 0]\n",
    "\n",
    "print(len(train_articles))\n",
    "print(len(train_labels))\n",
    "print(len(validation_articles))\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_articles)\n",
    "word_index = tokenizer.word_index\n",
    "train_sequences = tokenizer.texts_to_sequences(train_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "validation_sequences = tokenizer.texts_to_sequences(validation_articles)\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "training_label_seq = np.array(train_labels)\n",
    "validation_label_seq = np.array(validation_labels)\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 64)          320000    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 394,369\n",
      "Trainable params: 394,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "#    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    # Add a Dense layer with 6 units and softmax activation.\n",
    "    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-feda361be9ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_label_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_label_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"batch\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[1;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[0;32m    381\u001b[0m     dataset = dataset_ops.DatasetV2.zip((\n\u001b[0;32m    382\u001b[0m         \u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m     ))\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    564\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m     \"\"\"\n\u001b[1;32m--> 566\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   2763\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2764\u001b[0m     \u001b[1;34m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2765\u001b[1;33m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2766\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2767\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\data\\util\\structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[1;34m(element)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m           normalized_components.append(\n\u001b[1;32m--> 113\u001b[1;33m               ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[0;32m    114\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    256\u001b[0m   \"\"\"\n\u001b[0;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 258\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mae')\n",
    "num_epochs = 10\n",
    "history = model.fit(train_padded, training_label_seq, epochs=num_epochs, validation_data=(validation_padded, validation_label_seq), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label_seq[199:211,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
